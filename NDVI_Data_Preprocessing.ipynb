{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniebritton/Ecological-Drought-ML-Modeling/blob/main/NDVI_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Colab Set Up**"
      ],
      "metadata": {
        "id": "UexedQ1RAtJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly4tyIUWieEp"
      },
      "outputs": [],
      "source": [
        "# installs and import libraries\n",
        "!pip install matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "plt.rcParams[\"figure.figsize\"] = (20,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UINO1qT-ieEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import Data**"
      ],
      "metadata": {
        "id": "3DAyWO5_inej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the dataset only for the full range of NDVI data 2000 on\n",
        "df_ndvi = pd.read_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/NDVI_range_shorttermdrought.csv')\n",
        "df_ndvi['date'] = pd.to_datetime(df_ndvi['date']).dt.strftime('%Y-%m-%d')\n",
        "df_ndvi['date'] = pd.to_datetime(df_ndvi['date'])\n",
        "df_ndvi = df_ndvi.set_index('date')"
      ],
      "metadata": {
        "id": "RPTBxWGTjo9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import and create a list of pentads that the drought data is based on. \n",
        "# This will be used to calculate anomalies and average so that all of the \n",
        "# data variables match temporally\n",
        "pentads = pd.read_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/drought_variable_pentads.csv')\n",
        "pentads = pentads[1470:]\n",
        "pentads = pentads['date'].tolist()"
      ],
      "metadata": {
        "id": "6JtLnF76ptA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Calculate Anomalies**"
      ],
      "metadata": {
        "id": "niqDk55eiOkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that will calculate the daily mean for each variable and then \n",
        "# subsequently calculate the anomaly for each variable/day\n",
        "def calculate_anomaly(df, value_col):\n",
        "    \n",
        "    # Group the data by day of the year and calculate the average for each day of the year\n",
        "    df_daily_grouping = df.groupby(df.index.dayofyear).mean()\n",
        "\n",
        "    # Create a dictionary mapping day of year to average value\n",
        "    day_of_year_to_mean = df_daily_grouping[value_col].to_dict()\n",
        "\n",
        "    # Map the day of year to the average value for that day of year\n",
        "    df['day_of_year'] = df.index.dayofyear\n",
        "    df[f'day_of_year_{value_col}_mean'] = df['day_of_year'].map(day_of_year_to_mean)\n",
        "\n",
        "    # Calculate the daily anomaly as the difference between the original value and the average value for that day of year\n",
        "    df[f'{value_col}_anomaly'] = df[value_col] - df[f'day_of_year_{value_col}_mean']\n",
        "\n",
        "# NOTE - I am doing this before resampling we want to look at each day of the year here.\n",
        "# If we did this after resampling, because of the way the pentads work, we would have\n",
        "# less data to compare year to year.\n",
        "\n",
        "# Apply the function to each column of the dataframe\n",
        "for col in df_ndvi.columns:\n",
        "    if col != 'date':\n",
        "        calculate_anomaly(df_ndvi, col)"
      ],
      "metadata": {
        "id": "7cf3-H4Iy_Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the dataframe so that it only contains the anomaly data\n",
        "df_anom = df_ndvi[df_ndvi.columns[df_ndvi.columns.str.endswith('_anomaly')]]\n",
        "\n",
        "# Move the NDVI column to the first position in the dataframe\n",
        "df_anom.insert(0, 'NDVI_anomaly', df_anom.pop('NDVI_anomaly'))"
      ],
      "metadata": {
        "id": "jdzt-D2v5alv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Resample the Data to match the Pentads from the Drought Indexes, and Normalize**"
      ],
      "metadata": {
        "id": "SI14vXf36JNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS NARROWS THE DATA DOWN TO PENTADS - only have data every 5 days\n",
        "# create an empty list to store the result dataframes\n",
        "results = []\n",
        "\n",
        "# loop through each column in the dataframe\n",
        "for col in df_anom.columns:\n",
        "    if col == 'NDVI_anomaly':\n",
        "        result = pd.DataFrame({'date': pentads, f'{col}_roll': df_anom[col].rolling(window=30, min_periods=1).mean().loc[pentads]})\n",
        "    else:\n",
        "        result = pd.DataFrame({'date': pentads, f'{col}_roll': df_anom[col].rolling(window=30, min_periods=1).mean().loc[pentads]})\n",
        "    result = result.set_index('date')\n",
        "    results.append(result)\n",
        "\n",
        "# concatenate the result dataframes into a single dataframe\n",
        "anom_result = pd.concat(results, axis=1)\n",
        "\n",
        "# remove the first row since that row is not based on a 5-day average\n",
        "anom_result = anom_result[1:]\n",
        "\n",
        "# normalize the data\n",
        "normalized_df = (anom_result-anom_result.mean())/anom_result.std()"
      ],
      "metadata": {
        "id": "iIY3mEDNhGp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df"
      ],
      "metadata": {
        "id": "_5j-HPvMKkXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export**"
      ],
      "metadata": {
        "id": "kC0TZ5YlYSFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df.to_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/NDVI_clean_preprocessed_shorttermdrought.csv')"
      ],
      "metadata": {
        "id": "Tg1NIoT4YRfd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}