{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniebritton/Eco-Drought-South-Dakota/blob/main/NDVI_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Colab Set Up**"
      ],
      "metadata": {
        "id": "UexedQ1RAtJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly4tyIUWieEp"
      },
      "outputs": [],
      "source": [
        "# installs and import libraries\n",
        "!pip install geopandas \n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install lazypredict\n",
        "!pip install shap\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import lazypredict\n",
        "import shap\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "plt.rcParams[\"figure.figsize\"] = (20,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UINO1qT-ieEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2f2aaf-700d-4b2e-fa2e-b0c38f834ec6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Data**"
      ],
      "metadata": {
        "id": "3DAyWO5_inej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the dataset only for the full range of NDVI data 2000 on\n",
        "df_ndvi = pd.read_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/drought_NDVI_range_V2.csv')\n",
        "df_ndvi['date'] = pd.to_datetime(df_ndvi['date']).dt.strftime('%Y-%m-%d')\n",
        "df_ndvi['date'] = pd.to_datetime(df_ndvi['date'])\n",
        "df_ndvi = df_ndvi.set_index('date')\n",
        "# df_ndvi = df_ndvi.drop(['smam', 'smpm', 'PP_NDVI'], axis=1)"
      ],
      "metadata": {
        "id": "RPTBxWGTjo9z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import and create a list of pentads that the drought data is based on. \n",
        "# This will be used to calculate anomalies and average so that all of the \n",
        "# data variables match temporally\n",
        "pentads = pd.read_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/drought_variable_pentads.csv')\n",
        "pentads = pentads[1470:]\n",
        "pentads = pentads['date'].tolist()"
      ],
      "metadata": {
        "id": "6JtLnF76ptA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate Anomalies**"
      ],
      "metadata": {
        "id": "niqDk55eiOkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that will calculate the daily mean for each variable and then \n",
        "# subsequently calculate the anomaly for each variable/day\n",
        "def calculate_anomaly(df, value_col):\n",
        "    \n",
        "    # Group the data by day of the year and calculate the average for each day of the year\n",
        "    df_daily_grouping = df.groupby(df.index.dayofyear).mean()\n",
        "\n",
        "    # Create a dictionary mapping day of year to average value\n",
        "    day_of_year_to_mean = df_daily_grouping[value_col].to_dict()\n",
        "\n",
        "    # Map the day of year to the average value for that day of year\n",
        "    df['day_of_year'] = df.index.dayofyear\n",
        "    df[f'day_of_year_{value_col}_mean'] = df['day_of_year'].map(day_of_year_to_mean)\n",
        "\n",
        "    # Calculate the daily anomaly as the difference between the original value and the average value for that day of year\n",
        "    df[f'{value_col}_anomaly'] = df[value_col] - df[f'day_of_year_{value_col}_mean']\n",
        "\n",
        "# NOTE - I am doing this before resampling we want to look at each day of the year here.\n",
        "# If we did this after resampling, because of the way the pentads work, we would have\n",
        "# less data to compare year to year.\n",
        "\n",
        "# Apply the function to each column of the dataframe\n",
        "for col in df_ndvi.columns:\n",
        "    if col != 'date':\n",
        "        calculate_anomaly(df_ndvi, col)"
      ],
      "metadata": {
        "id": "7cf3-H4Iy_Rs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the dataframe so that it only contains the anomaly data\n",
        "df_anom = df_ndvi[df_ndvi.columns[df_ndvi.columns.str.endswith('_anomaly')]]\n",
        "\n",
        "# Move the NDVI column to the first position in the dataframe\n",
        "df_anom.insert(0, 'NDVI_anomaly', df_anom.pop('NDVI_anomaly'))"
      ],
      "metadata": {
        "id": "jdzt-D2v5alv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resample the Data to match the Pentads from the Drought Indexes, and Normalize**"
      ],
      "metadata": {
        "id": "SI14vXf36JNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS NARROWS THE DATA DOWN TO PENTADS - only have data every 5 days\n",
        "# create an empty list to store the result dataframes\n",
        "results = []\n",
        "\n",
        "# loop through each column in the dataframe\n",
        "for col in df_anom.columns:\n",
        "    if col == 'NDVI_anomaly':\n",
        "        result = pd.DataFrame({'date': pentads, f'{col}_roll': df_anom[col].rolling(window=30, min_periods=1).mean().loc[pentads]})\n",
        "    else:\n",
        "        result = pd.DataFrame({'date': pentads, f'{col}_roll': df_anom[col].rolling(window=30, min_periods=1).mean().loc[pentads]})\n",
        "    result = result.set_index('date')\n",
        "    results.append(result)\n",
        "\n",
        "# concatenate the result dataframes into a single dataframe\n",
        "anom_result = pd.concat(results, axis=1)\n",
        "\n",
        "# remove the first row since that row is not based on a 5-day average\n",
        "anom_result = anom_result[1:]\n",
        "\n",
        "# normalize the data\n",
        "normalized_df = (anom_result-anom_result.mean())/anom_result.std()"
      ],
      "metadata": {
        "id": "iIY3mEDNhGp7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize**"
      ],
      "metadata": {
        "id": "XDJ9FJxa8t2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = normalized_df['pdsi_anomaly_roll']\n",
        "c = normalized_df['NDVI_anomaly_roll']\n",
        "fig, ax = plt.subplots(1,1, )\n",
        "ax.plot(b, label='PDSI')\n",
        "ax.plot(c, label='NDVI')\n",
        "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks = 15))\n",
        "ax.legend()\n",
        "plt.title(\"NDVI 30 Day Rolling Mean\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BvOD5CLShSCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prelim ML Tests**"
      ],
      "metadata": {
        "id": "WeUTo__m8Z4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try a random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# add in a boolean drought column (1 for drought, 0 for no drought)\n",
        "normalized_df['drought_bool'] = np.where(normalized_df[\"pdsi_anomaly_roll\"] >= 0, 0, 1)\n",
        "\n",
        "X = normalized_df.iloc[:,0:15].values\n",
        "Y = normalized_df.iloc[:,15:16].values.ravel()\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# SUBSET YOUR X AND Y INTO TRAIN/TEST SETS; for instance, take first 80% of the rows as training, last 20% as test\n",
        "X_train = normalized_df.iloc[0:1272, 0:15].values\n",
        "Y_train = normalized_df.iloc[0:1272, 15:16].values.ravel()\n",
        "X_test = normalized_df.iloc[1272:1590, 0:15].values\n",
        "Y_test = normalized_df.iloc[1272:1590, 15:16].values\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_predicted = clf.predict(X_test)\n",
        "\n",
        "# compare Y_predicted with Y_test\n",
        "clf.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "mx-IfOnGMixG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try a decision tree regressor\n",
        "from sklearn import tree\n",
        "\n",
        "X = normalized_df.iloc[:,1:15].values\n",
        "Y = normalized_df.iloc[:,0:1].values.ravel()\n",
        "\n",
        "clf = tree.DecisionTreeRegressor()\n",
        "\n",
        "X_train = normalized_df.iloc[0:1272, 1:15].values\n",
        "Y_train = normalized_df.iloc[0:1272, 0:1].values.ravel()\n",
        "X_test = normalized_df.iloc[1272:1590, 1:15].values\n",
        "Y_test = normalized_df.iloc[1272:1590, 0:1].values\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_predicted = clf.predict(X_test)\n",
        "\n",
        "# compare Y_predicted with Y_test\n",
        "clf.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "ogtEHwEG2LDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try support vector regression\n",
        "from sklearn import svm\n",
        "\n",
        "X = normalized_df.iloc[:,1:15].values\n",
        "Y = normalized_df.iloc[:,0:1].values.ravel()\n",
        "\n",
        "regr = svm.SVR()\n",
        "\n",
        "X_train = normalized_df.iloc[0:1272, 1:15].values\n",
        "Y_train = normalized_df.iloc[0:1272, 0:1].values.ravel()\n",
        "X_test = normalized_df.iloc[1272:1590, 1:15].values\n",
        "Y_test = normalized_df.iloc[1272:1590, 0:1].values\n",
        "\n",
        "regr.fit(X_train, Y_train)\n",
        "Y_predicted = regr.predict(X_test)\n",
        "\n",
        "# compare Y_predicted with Y_test\n",
        "regr.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "y76bC02i7Tks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying Out LazyPredict**"
      ],
      "metadata": {
        "id": "a7ZGlZDb7_PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install and import\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "from lazypredict.Supervised import LazyClassifier"
      ],
      "metadata": {
        "id": "qFErvjkI7-2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification\n",
        "# add in a boolean drought column (1 for drought, 0 for no drought)\n",
        "normalized_df['drought_bool'] = np.where(normalized_df[\"pdsi_anomaly_roll\"] >= 0, 0, 1)\n",
        "\n",
        "X_train = normalized_df.iloc[0:1272, 0:15].values\n",
        "y_train = normalized_df.iloc[0:1272, 15:16].values.ravel()\n",
        "\n",
        "X_test = normalized_df.iloc[1272:1590, 0:15].values\n",
        "y_test = normalized_df.iloc[1272:1590, 15:16].values\n",
        "\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "cmodel,cprediction = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "cmodel"
      ],
      "metadata": {
        "id": "WDy8qBZm8Vx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression\n",
        "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "\n",
        "X_train = normalized_df.iloc[0:1272, 0:15].values\n",
        "y_train = normalized_df.iloc[0:1272, 15:16].values.ravel()\n",
        "\n",
        "X_test = normalized_df.iloc[1272:1590, 0:15].values\n",
        "y_test = normalized_df.iloc[1272:1590, 15:16].values\n",
        "\n",
        "rmodel, rprediction = reg.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "rmodel"
      ],
      "metadata": {
        "id": "-GP502158ZNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold Cross Validation for Lazy Predict Regression**"
      ],
      "metadata": {
        "id": "d9xiEeiCVVx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold_lp(data, target, k=5):\n",
        "    # Create a KFold object with k folds\n",
        "    kf = KFold(n_splits=k, shuffle = True, random_state=42)\n",
        "    # Create an empty df to store scores for each fold\n",
        "    scores = pd.DataFrame()\n",
        "    # Loop over each fold\n",
        "    for train_idx, test_idx in kf.split(data):\n",
        "        # Split the data into train and test sets for this fold\n",
        "        X_train, X_test = data[train_idx], data[test_idx]\n",
        "        y_train, y_test = target[train_idx], target[test_idx]\n",
        "        # Create a LazyRegressor model\n",
        "        reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "        # Fit the model on the train data and make predictions on the test data\n",
        "        models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "        # Append the score to the list of scores for this fold\n",
        "        scores = scores.append(predictions)\n",
        "    # Calculate the mean of all scores across all folds\n",
        "    return scores"
      ],
      "metadata": {
        "id": "ibHLivwwLC1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "\n",
        "mean_score = k_fold_lp(X, y)\n",
        "mean_score = mean_score.sort_values(by = \"Adjusted R-Squared\", ascending = False)"
      ],
      "metadata": {
        "id": "sGuZtYjyLYMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_score.groupby(\"Model\").mean().sort_values(by = \"Adjusted R-Squared\", ascending = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qsv6hpHs-7tr",
        "outputId": "0740c874-1b48-4375-a6b2-8f27d270ae8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
              "Model                                                                         \n",
              "GaussianProcessRegressor                     0.93       0.93  0.26        0.26\n",
              "ExtraTreesRegressor                          0.93       0.93  0.26        0.69\n",
              "LGBMRegressor                                0.89       0.89  0.32        0.27\n",
              "HistGradientBoostingRegressor                0.89       0.89  0.32        1.05\n",
              "XGBRegressor                                 0.89       0.89  0.32        0.60\n",
              "RandomForestRegressor                        0.87       0.88  0.34        1.76\n",
              "BaggingRegressor                             0.86       0.86  0.37        0.18\n",
              "KNeighborsRegressor                          0.82       0.82  0.42        0.04\n",
              "GradientBoostingRegressor                    0.78       0.79  0.46        0.86\n",
              "MLPRegressor                                 0.77       0.78  0.46        3.22\n",
              "SVR                                          0.77       0.78  0.47        0.18\n",
              "NuSVR                                        0.76       0.77  0.47        0.29\n",
              "ExtraTreeRegressor                           0.71       0.72  0.52        0.05\n",
              "DecisionTreeRegressor                        0.70       0.72  0.52        0.08\n",
              "AdaBoostRegressor                            0.67       0.68  0.56        0.34\n",
              "KernelRidge                                  0.48       0.50  0.70        0.13\n",
              "Ridge                                        0.48       0.50  0.70        0.03\n",
              "RidgeCV                                      0.48       0.50  0.70        0.04\n",
              "LinearRegression                             0.48       0.50  0.70        0.04\n",
              "TransformedTargetRegressor                   0.48       0.50  0.70        0.02\n",
              "SGDRegressor                                 0.47       0.50  0.70        0.06\n",
              "BayesianRidge                                0.47       0.50  0.70        0.03\n",
              "LassoLarsIC                                  0.47       0.50  0.70        0.05\n",
              "HuberRegressor                               0.47       0.49  0.71        0.08\n",
              "LassoCV                                      0.47       0.49  0.71        0.23\n",
              "LassoLarsCV                                  0.47       0.49  0.71        0.09\n",
              "ElasticNetCV                                 0.47       0.49  0.71        0.23\n",
              "OrthogonalMatchingPursuitCV                  0.46       0.48  0.72        0.07\n",
              "LinearSVR                                    0.46       0.48  0.72        0.06\n",
              "LarsCV                                       0.42       0.45  0.74        0.08\n",
              "TweedieRegressor                             0.41       0.44  0.75        0.13\n",
              "OrthogonalMatchingPursuit                    0.33       0.36  0.80        0.04\n",
              "ElasticNet                                   0.04       0.08  0.96        0.02\n",
              "QuantileRegressor                           -0.05      -0.00  1.00       55.19\n",
              "DummyRegressor                              -0.05      -0.00  1.00        0.02\n",
              "Lasso                                       -0.05      -0.00  1.00        0.03\n",
              "LassoLars                                   -0.05      -0.00  1.00        0.04\n",
              "PassiveAggressiveRegressor                  -0.29      -0.23  1.09        0.05\n",
              "RANSACRegressor                             -0.33      -0.27  1.11        0.42\n",
              "Lars                                       -21.31     -20.32  4.19        0.04"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-479e1159-4ea3-4146-be09-a836c1adb085\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adjusted R-Squared</th>\n",
              "      <th>R-Squared</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GaussianProcessRegressor</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesRegressor</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMRegressor</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HistGradientBoostingRegressor</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBRegressor</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingRegressor</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsRegressor</th>\n",
              "      <td>0.82</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingRegressor</th>\n",
              "      <td>0.78</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPRegressor</th>\n",
              "      <td>0.77</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.46</td>\n",
              "      <td>3.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>0.77</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVR</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeRegressor</th>\n",
              "      <td>0.71</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeRegressor</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KernelRidge</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransformedTargetRegressor</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDRegressor</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BayesianRidge</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsIC</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HuberRegressor</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsCV</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNetCV</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuitCV</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVR</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LarsCV</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TweedieRegressor</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuit</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuantileRegressor</th>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>55.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyRegressor</th>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLars</th>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveRegressor</th>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RANSACRegressor</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lars</th>\n",
              "      <td>-21.31</td>\n",
              "      <td>-20.32</td>\n",
              "      <td>4.19</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-479e1159-4ea3-4146-be09-a836c1adb085')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-479e1159-4ea3-4146-be09-a836c1adb085 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-479e1159-4ea3-4146-be09-a836c1adb085');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Fold on Individual Models**"
      ],
      "metadata": {
        "id": "ISqEoF-kvijo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "#X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "# Define your model\n",
        "gpr_model = GaussianProcessRegressor()\n",
        "\n",
        "# Define the number of folds for cross validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the k-fold cross validation object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(gpr_model, X, y, cv=kfold, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcadec5b-710d-412d-a77c-2dee69ef11e6",
        "id": "rBFgdydyvSBA"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0.90848108 0.93312081 0.95463627 0.95008162 0.91378848]\n",
            "Mean Result: 0.9320216516154775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "#X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "# Define your model\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "# Define the number of folds for cross validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the k-fold cross validation object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(xgb_model, X, y, cv=kfold, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSYyR4WgoMHo",
        "outputId": "56cec150-95f5-44f3-e01a-9476428fd73e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0.87942551 0.91035714 0.85577327 0.92265321 0.8955487 ]\n",
            "Mean Result: 0.8927515641699184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "#X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "# Define your model\n",
        "lgb_model = lgb.LGBMRegressor()\n",
        "\n",
        "# Define the number of folds for cross validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the k-fold cross validation object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(lgb_model, X, y, cv=kfold, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vQUqkh9uWZs",
        "outputId": "775dc1a7-99f6-48fc-b8f8-251c64c3c06a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0.87556781 0.90804599 0.84585091 0.92306873 0.89468476]\n",
            "Mean Result: 0.8894436396265274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying Different Cross Val Strategies**"
      ],
      "metadata": {
        "id": "dbUDMCOLwIO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "\n",
        "# Define your model\n",
        "gpr_model = GaussianProcessRegressor()\n",
        "\n",
        "# Define the cross validation object\n",
        "ss = ShuffleSplit(n_splits=5, test_size=0.10, random_state=42)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(gpr_model, X, y, cv=ss, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "id": "2AgArHLIwLZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eff03da-251b-4c17-e5fc-95798fce917d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0.93139087 0.9318324  0.94931258 0.92927714 0.94937186]\n",
            "Mean Result: 0.9382369681890103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "\n",
        "# Define your model\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "# Define the number of folds for cross validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the cross validation object\n",
        "ss = ShuffleSplit(n_splits=5, test_size=0.20, random_state=42)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(xgb_model, X, y, cv=ss, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejQ7Fs2WwOsj",
        "outputId": "ecee4d86-4df7-439e-9179-0cf681895592"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0.87942551 0.89157883 0.90930349 0.89146379 0.88331694]\n",
            "Mean Result: 0.891017712220558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "\n",
        "# Define your model\n",
        "gpr_model = GaussianProcessRegressor()\n",
        "\n",
        "# Define the cross validation object\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Run k-fold cross validation on the model\n",
        "results = cross_val_score(gpr_model, X, y, cv=tscv, scoring='r2')\n",
        "\n",
        "# Print the mean and standard deviation of the results\n",
        "print(\"Results:\", results)\n",
        "print(\"Mean Result:\", results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqaIw9qQxM1U",
        "outputId": "5eebb670-3ead-44a4-aa27-8da44d2b72b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [ 0.31084768  0.12768828  0.13549229 -0.12182628 -0.02038459]\n",
            "Mean Result: 0.08636347330274827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization**"
      ],
      "metadata": {
        "id": "9g_Q-aQrJLan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "X = normalized_df.iloc[:, 1:15].values\n",
        "y = normalized_df.iloc[:, 0:1].values.ravel()\n",
        "\n",
        "# define the model\n",
        "model = XGBRegressor()\n",
        "\n",
        "# define the hyperparameter grid\n",
        "hyperparameters = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "#     'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
        "#     'colsample_bytree': [0.3, 0.4, 0.5, 0.7, 0.9],\n",
        "#     'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
        "#     'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "# }\n",
        "\n",
        "# define the random search object\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,         # specify the model to use\n",
        "    param_distributions=hyperparameters,  # specify the hyperparameter grid to search over\n",
        "    n_iter=50,               # specify the number of combinations of hyperparameters to try\n",
        "    cv=5,                    # specify the number of cross-validation folds to use\n",
        "    n_jobs=-1,               # specify the number of CPU cores to use (-1 means use all available cores)\n",
        "    scoring='neg_mean_squared_error'   # specify the metric to optimize for\n",
        ")\n",
        "\n",
        "# perform the random search\n",
        "random_search.fit(X, y)\n",
        "\n",
        "# print the best hyperparameters\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best score:\", random_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRMIeDTyHTHp",
        "outputId": "fec5e41d-9220-4948-9d20-361d32015198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 100, 'max_depth': 6}\n",
            "-0.5123562568811239\n"
          ]
        }
      ]
    }
  ]
}