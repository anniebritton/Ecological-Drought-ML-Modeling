{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iyfGZfn1VjPtJCO2PofI4VMoUibj83HG",
      "authorship_tag": "ABX9TyNYieZC8vF7+dxNxVCEMqjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniebritton/Ecological-Drought-ML-Modeling/blob/main/NDVI_Data_Acquisition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Colab Set Up**"
      ],
      "metadata": {
        "id": "UexedQ1RAtJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsdTWCFTqd7b"
      },
      "outputs": [],
      "source": [
        "# installs and import libraries\n",
        "!pip install earthengine-api --upgrade\n",
        "!pip install geemap\n",
        "!pip install geopandas \n",
        "!pip install matplotlib\n",
        "!pip install pyshp\n",
        "!pip install PyCRS\n",
        "\n",
        "\n",
        "import ee\n",
        "import shapefile\n",
        "import geemap.foliumap as geemap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise ee, copy and paste the authentication code\n",
        "try:\n",
        "        ee.Initialize()\n",
        "except Exception as e:\n",
        "        ee.Authenticate()\n",
        "        ee.Initialize()"
      ],
      "metadata": {
        "id": "8NkWhKCLtZMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount gogole drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cA0z12MruON6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import and create a variable for the shapefile\n",
        "AOI_path = '/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/Shapefiles/Cheyenne_Basin/Cheyenne_Basin_whole.shp'\n",
        "\n",
        "# convert the shapefile into an Earth Engine object\n",
        "AOI = geemap.shp_to_ee(AOI_path)"
      ],
      "metadata": {
        "id": "dpc7IYMRuQtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setting up the masking and preprocessing for the MODIS NDVI Data**"
      ],
      "metadata": {
        "id": "kQPZDMQCU4F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, a function to mask out cloudy pixels\n",
        "def mask_clouds(image):\n",
        "    # Select the QA band\n",
        "    QA = image.select('state_1km')\n",
        "    # Make a mask to get bit 10, the internal cloud algorithm flag bit\n",
        "    bit_mask = 1 << 10\n",
        "    # Return an image masking out cloudy areas\n",
        "    return image.updateMask(QA.bitwiseAnd(bit_mask).eq(0))\n",
        "\n",
        "\n",
        "# Next, a function to mask out pixels with snow\n",
        "def mask_snow(image):\n",
        "    # Select the QA band\n",
        "    QA = image.select('state_1km')\n",
        "    # Make a mask to get bit 15, the internal snow mask bit\n",
        "    bit_mask = 1 << 15\n",
        "    # Return an image masking out snowy areas\n",
        "    return image.updateMask(QA.bitwiseAnd(bit_mask).eq(0))\n",
        "\n",
        "\n",
        "# Get MODIS surface reflectance image collection\n",
        "mod09ga = ee.ImageCollection(\"MODIS/006/MOD09GA\")\n",
        "\n",
        "# Filter image collections by date and apply the mask_clouds and mask_snow functions\n",
        "mod09ga_masked = mod09ga.filterDate('2000-02-24', '2021-12-31').map(mask_clouds).map(mask_snow)"
      ],
      "metadata": {
        "id": "jwEUsqT9lJZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, a function to calculate and create a new NDVI band\n",
        "def get_NDVI(imagecol):\n",
        "    ndvi = imagecol.normalizedDifference(['sur_refl_b02', 'sur_refl_b01']).rename(\"NDVI\")\n",
        "    return imagecol.addBands(ndvi).select('NDVI').copyProperties(imagecol)\n",
        "\n",
        "# Add NDVI as a band to the image\n",
        "mod09ga_NDVI = mod09ga_masked.map(get_NDVI)"
      ],
      "metadata": {
        "id": "h-iqYt_vlNPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Set Up**"
      ],
      "metadata": {
        "id": "Mz_0QHvUBPp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODIS NDVI\n",
        "NDVI_list = [mod09ga_NDVI, 'NDVI', AOI, 1000 ]\n",
        "\n",
        "# Daymet\n",
        "swe_list = [ee.ImageCollection(\"NASA/ORNL/DAYMET_V4\").filterDate('2000-02-24','2021-12-31'), 'swe', AOI, 1000]\n",
        "\n",
        "# gridMET Meteorology\n",
        "tmin_list = [ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\").filterDate('2000-02-24','2021-12-31'), 'tmmn', AOI, 4638.3]\n",
        "tmax_list = [ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\").filterDate('2000-02-24','2021-12-31'), 'tmmx', AOI, 4638.3]\n",
        "precip_list = [ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\").filterDate('2000-02-24','2021-12-31'), 'pr', AOI, 4638.3]\n",
        "\n",
        "# gridMET Drought\n",
        "pdsi_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'pdsi', AOI, 4638.3]\n",
        "palmerz_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'z', AOI, 4638.3]\n",
        "\n",
        "spei30_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spei30d', AOI, 4638.3]\n",
        "spei90_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spei90d', AOI, 4638.3]\n",
        "spei180_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spei180d', AOI, 4638.3]\n",
        "\n",
        "spi30_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spi30d', AOI, 4638.3]\n",
        "spi90_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spi90d', AOI, 4638.3]\n",
        "spi180_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'spi180d', AOI, 4638.3]\n",
        "\n",
        "eddi30_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'eddi30d', AOI, 4638.3]\n",
        "eddi90_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'eddi90d', AOI, 4638.3]\n",
        "eddi180_list = [ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2000-02-24','2021-12-31'), 'eddi180d', AOI, 4638.3]"
      ],
      "metadata": {
        "id": "VePMHPb08dti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function for Creating a Timeseries of Spatially Averaged Data**"
      ],
      "metadata": {
        "id": "YdX0AoocWa58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spatialtimeseries(datalist):\n",
        "  \n",
        "    data = datalist[0]\n",
        "    band = datalist[1]\n",
        "    geometry = datalist[2]\n",
        "    scale = datalist[3]\n",
        "\n",
        "    # reduce the image collection to the area of study and to the correct bands\n",
        "    def aoi_mean(img):\n",
        "        mean = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=geometry, scale=scale).get(band)\n",
        "        return img.set('date', img.date().format()).set('mean', mean)\n",
        "\n",
        "    # Map this function to every image in our collection to get a new \n",
        "    # ImageCollection, but now each image has the mean value for the region of interest and the date. \n",
        "    aoi_reduced_imgs = data.map(aoi_mean)\n",
        "\n",
        "    # Reduce the images to a list of lists:\n",
        "    # for each image, we have a 2-element list that contains that images date and mean value (for our point of interest)\n",
        "    # each of these lists are themselves elements in our outer list, which is what weâ€™ll convert to a dataframe\n",
        "    nested_list = aoi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date','mean']).values().get(0)\n",
        "\n",
        "    # This nested list can be turned into a dataframe using the .DataFrame constructor.\n",
        "    # Call the callback method \"getInfo\" to retrieve the data\n",
        "    df = pd.DataFrame(nested_list.getInfo(), columns=['date','mean'])\n",
        "\n",
        "    # Set the date column to be the index.\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
        "    df = df.set_index('date')\n",
        "\n",
        "    return(df)"
      ],
      "metadata": {
        "id": "Jurm8nhL5h3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NDVI\n",
        "NDVI_df = spatialtimeseries(NDVI_list)"
      ],
      "metadata": {
        "id": "LC8gNqHAWI2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daymet\n",
        "swe_df = spatialtimeseries(swe_list)"
      ],
      "metadata": {
        "id": "K3TZrTCWYF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gridMET Meteorology\n",
        "tmin_df = spatialtimeseries(tmin_list)\n",
        "tmax_df = spatialtimeseries(tmax_list)\n",
        "precip_df = spatialtimeseries(precip_list)"
      ],
      "metadata": {
        "id": "G_k4_6wdYGDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gridMET Drought\n",
        "pdsi_df = spatialtimeseries(pdsi_list)\n",
        "palmerz_df = spatialtimeseries(palmerz_list)"
      ],
      "metadata": {
        "id": "nYINr6MKYGIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eddi30_df = spatialtimeseries(eddi30_list)\n",
        "eddi90_df = spatialtimeseries(eddi90_list)\n",
        "eddi180_df = spatialtimeseries(eddi180_list)"
      ],
      "metadata": {
        "id": "_fJoOrBC5vq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spei30_df = spatialtimeseries(spei30_list)\n",
        "spei90_df = spatialtimeseries(spei90_list)\n",
        "spei180_df = spatialtimeseries(spei180_list)"
      ],
      "metadata": {
        "id": "9ZWUou3k5p8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spi30_df = spatialtimeseries(spi30_list)\n",
        "spi90_df = spatialtimeseries(spi90_list)\n",
        "spi180_df = spatialtimeseries(spi180_list)"
      ],
      "metadata": {
        "id": "2mHBO0LG5qHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Concatenate Dataframes**"
      ],
      "metadata": {
        "id": "7YlH1vdo85Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of the dataframe names\n",
        "df_list = [swe_df, tmin_df, tmax_df, precip_df, pdsi_df, palmerz_df,\n",
        "eddi30_df, eddi90_df, eddi180_df,  \n",
        "spei30_df, spei90_df, spei180_df,  \n",
        "spi30_df, spi90_df, spi180_df, \n",
        "NDVI_df]\n",
        "\n",
        "# Create a list of the variables names\n",
        "var_names = ['swe', 'tmin', 'tmax', 'precip', 'pdsi', \"palmerz\",\n",
        "'eddi30', 'eddi90', 'eddi180', \n",
        "'spei30', 'spei90', 'spei180',\n",
        "'spi30', 'spi90', 'spi180', \n",
        "'NDVI']\n",
        "\n",
        "# Create an empty dataframe to fill\n",
        "df_whole = pd.DataFrame()\n",
        "\n",
        "# Set the index to match the index of the data \n",
        "# using tmin because it runs for the full daily series of data\n",
        "df_whole.index = tmin_df.index\n",
        "\n",
        "# For loop that adds each column to the new df and renames it\n",
        "for i, df in enumerate(df_list):\n",
        "  df_whole[var_names[i]] = df['mean']\n",
        "\n",
        "# reset the index to avoid annoying datetime issues\n",
        "df_whole = df_whole.reset_index()\n",
        "df_whole['date'] = pd.to_datetime(df_whole['date'], utc=True)\n",
        "df_whole = df_whole.set_index('date')"
      ],
      "metadata": {
        "id": "crPzF0byVQUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_whole"
      ],
      "metadata": {
        "id": "7wszU11_JURN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_whole.to_csv('/content/drive/MyDrive/School/M.S./Courses/Capstone/Colab/Data/CSVs/NDVI_range_shorttermdrought.csv')"
      ],
      "metadata": {
        "id": "FVNDvxOCFBsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}